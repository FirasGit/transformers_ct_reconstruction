{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from gptnano.translator import VQGANTransformer\n",
    "from utils import load_data, plot_images\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import itertools\n",
    "from contextlib import nullcontext\n",
    "\n",
    "from metrics import Structural_Similarity\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "\tnum_codebook_vectors = 8192\n",
    "\tcheckpoint_path_3d_vqgan = '' # Path to the best 3D VQ-GAN model checkpoint\n",
    "\tcheckpoint_path_2d_vqgan = '' # Path to the best 2D VQ-GAN model checkpoint\n",
    "\tcheckpoint_path_gpt = '' # Path to the best GPT model checkpoint (located under .../gpt_results/run_X/checkpoint/transformer_X_X.pt)\n",
    "\tpkeep = 0.5\n",
    "\tsos_token = 0\n",
    "\tblock_size = 4096 + 256 * 2\n",
    "\tn_unmasked = 256 * 2 + 1\n",
    "\tdevice = \"cuda:0\"\n",
    "\tbatch_size = 1\n",
    "\tepochs = 100\n",
    "\tlearning_rate = 2.25e-05\n",
    "\tnum_workers = 1\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQGANTransformer(args).to(device=args.device)\n",
    "\n",
    "model.load_gpt(args, strict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_data(args)\n",
    "\n",
    "index= 192\n",
    "data = next(itertools.islice(iter(test_dataloader), index, None))\n",
    "\n",
    "imgs_ct = data['indices_ct']\n",
    "imgs_ap = data['indices_ap']\n",
    "imgs_lat = data['indices_lat']\n",
    "\n",
    "imgs_ct = imgs_ct.to(device=args.device)\n",
    "imgs_ap = imgs_ap.to(device=args.device)\n",
    "imgs_lat = imgs_lat.to(device=args.device)\n",
    "\n",
    "orig_ct = np.load(data['file_name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=args.device\n",
    "dtype = 'bfloat16'\n",
    "\n",
    "# for later use in torch.autocast\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32,\n",
    "            'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(\n",
    "    device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "with ctx:\n",
    "    log, sampled_imgs_ct, sampled_imgs_ap, sampled_imgs_lat = model.log_images(\n",
    "                        (imgs_ct[0][None], imgs_ap[0][None], imgs_lat[0][None]), temperature=1.0, top_k=100)\n",
    "\n",
    "sampled_imgs_ct = sampled_imgs_ct.float()\n",
    "sampled_imgs_ap = sampled_imgs_ap.float()\n",
    "sampled_imgs_lat = sampled_imgs_lat.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for slide in range(0, len(orig_ct), 10):\n",
    "\t# Plot the results side by side\n",
    "\timages = {'CT Full reconstruction': sampled_imgs_ct.detach().cpu()[2][0][slide], 'CT Half reconstruction': sampled_imgs_ct.detach().cpu()[1][0][slide], 'Reconstructed (no GPT)': sampled_imgs_ct.detach().cpu()[0][0][slide], 'Original CT': orig_ct[slide]}\n",
    "\tfig, ax = plt.subplots(1, len(images), figsize=(20, 20))\n",
    "\tfor i, (title, image) in enumerate(images.items()):\n",
    "\t\tax[i].imshow(image, cmap='gray')\n",
    "\t\tax[i].axis('off')\n",
    "\t\tax[i].set_title(title)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results side by side\n",
    "\n",
    "images = {'CT Full reconstruction': sampled_imgs_ct.detach().cpu()[2][0], 'CT Half reconstruction': sampled_imgs_ct.detach().cpu()[1][0], 'Reconstructed (no GPT)': sampled_imgs_ct.detach().cpu()[0][0], 'Original CT': orig_ct}\n",
    "fig, ax = plt.subplots(1, 2 * len(images), figsize=(20, 20))\n",
    "i = 0\n",
    "for title, image in images.items():\n",
    "\tax[i].imshow(np.flip(np.mean(np.array(image), axis=1), 0), cmap='gray')\n",
    "\tax[i].axis('off')\n",
    "\tax[i].set_title(title)\n",
    "\n",
    "\tax[i + 1].imshow(np.flip(np.mean(np.array(image), axis=2), 0), cmap='gray')\n",
    "\tax[i + 1].axis('off')\n",
    "\tax[i + 1].set_title(title)\n",
    "\ti+=2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results side by side\n",
    "SLICE_IDX = 60\n",
    "\n",
    "images = {'CT Full reconstruction': sampled_imgs_ct.detach().cpu()[2][0], 'CT Half reconstruction': sampled_imgs_ct.detach().cpu()[1][0], 'Reconstructed (no GPT)': sampled_imgs_ct.detach().cpu()[0][0], 'Original CT': orig_ct}\n",
    "fig, ax = plt.subplots(len(images), 3, figsize=(20, 20))\n",
    "i = 0\n",
    "for title, image in images.items():\n",
    "\tax[i][0].imshow(np.flip(np.array(image[:, SLICE_IDX, :]), 0), cmap='gray')\n",
    "\tax[i][0].axis('off')\n",
    "\tax[i][0].set_title(title)\n",
    "\n",
    "\tax[i][1].imshow(np.flip(np.array(image[:, :, SLICE_IDX]), 0), cmap='gray')\n",
    "\tax[i][1].axis('off')\n",
    "\tax[i][1].set_title(title)\n",
    "\n",
    "\tax[i][2].imshow(np.flip(np.array(image[SLICE_IDX, :, :]), 0), cmap='gray')\n",
    "\tax[i][2].axis('off')\n",
    "\tax[i][2].set_title(title)\n",
    "\ti += 1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x2ct_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e57f99a62812bf754688c50e8ec7c45df4e600ea8ca1cb4c958cb0a42792f43b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
